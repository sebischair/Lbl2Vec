{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set: \n",
    "https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv\n",
    "\n",
    "The AG's news topic classification dataset is constructed by choosing the 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600. \n",
    "\n",
    "The classes are: \n",
    "\n",
    "* World\n",
    "* Sports\n",
    "* Business\n",
    "* Science/Technology\n",
    "\n",
    "#### For more information on how to use Lbl2Vec, visit the [API Guide](https://lbl2vec.readthedocs.io/en/latest/api.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbl2vec import Lbl2Vec\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "ag_train = pd.read_csv('data/train.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load test data\n",
    "ag_test = pd.read_csv('data/test.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load labels with keywords\n",
    "labels = pd.read_csv('data/labels.csv',sep=';')\n",
    "\n",
    "# split keywords by separator and save them as array\n",
    "labels['keywords'] = labels['keywords'].apply(lambda x: x.split(' '))\n",
    "\n",
    "# convert description keywords to lowercase\n",
    "labels['keywords'] = labels['keywords'].apply(lambda description_keywords: [keyword.lower() for keyword in description_keywords])\n",
    "\n",
    "# get number of keywords for each class\n",
    "labels['number_of_keywords'] = labels['keywords'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>[election, state, president, police, politics,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "      <td>[olympic, football, sport, league, baseball, r...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>[company, market, oil, consumers, exchange, bu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>[laboratory, computers, science, technology, w...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_index          class_name  \\\n",
       "0            1               World   \n",
       "1            2              Sports   \n",
       "2            3            Business   \n",
       "3            4  Science/Technology   \n",
       "\n",
       "                                            keywords  number_of_keywords  \n",
       "0  [election, state, president, police, politics,...                  11  \n",
       "1  [olympic, football, sport, league, baseball, r...                  32  \n",
       "2  [company, market, oil, consumers, exchange, bu...                  10  \n",
       "3  [laboratory, computers, science, technology, w...                  18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc: document text string\n",
    "# returns tokenized document\n",
    "# strip_tags removes meta tags from the text\n",
    "# simple preprocess converts a document into a list of lowercase tokens, ignoring tokens that are too short or too long \n",
    "# simple preprocess also removes numerical values as well as punktuation characters\n",
    "def tokenize(doc):\n",
    "    return simple_preprocess(strip_tags(doc), deacc=True, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data set type column\n",
    "ag_train['data_set_type'] = 'train'\n",
    "ag_test['data_set_type'] = 'test'\n",
    "\n",
    "# concat train and test data\n",
    "ag_full_corpus = pd.concat([ag_train,ag_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and tag documents combined title + description for Lbl2Vec training\n",
    "ag_full_corpus['tagged_docs'] = ag_full_corpus.apply(lambda row: TaggedDocument(tokenize(row['title'] + '. ' + row['description']), [str(row.name)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add doc_key column\n",
    "ag_full_corpus['doc_key'] = ag_full_corpus.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class_name column\n",
    "ag_full_corpus = ag_full_corpus.merge(labels, left_on='class', right_on='class_index', how='left').drop(['class', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>data_set_type</th>\n",
       "      <th>tagged_docs</th>\n",
       "      <th>doc_key</th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>train</td>\n",
       "      <td>([wall, st, bears, claw, back, into, the, blac...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>train</td>\n",
       "      <td>([carlyle, looks, toward, commercial, aerospac...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>train</td>\n",
       "      <td>([oil, and, economy, cloud, stocks, outlook, r...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>train</td>\n",
       "      <td>([iraq, halts, oil, exports, from, main, south...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>train</td>\n",
       "      <td>([oil, prices, soar, to, all, time, record, po...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description data_set_type  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...         train   \n",
       "1  Reuters - Private investment firm Carlyle Grou...         train   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...         train   \n",
       "3  Reuters - Authorities have halted oil export\\f...         train   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...         train   \n",
       "\n",
       "                                         tagged_docs doc_key  class_index  \\\n",
       "0  ([wall, st, bears, claw, back, into, the, blac...       0            3   \n",
       "1  ([carlyle, looks, toward, commercial, aerospac...       1            3   \n",
       "2  ([oil, and, economy, cloud, stocks, outlook, r...       2            3   \n",
       "3  ([iraq, halts, oil, exports, from, main, south...       3            3   \n",
       "4  ([oil, prices, soar, to, all, time, record, po...       4            3   \n",
       "\n",
       "  class_name  number_of_keywords  \n",
       "0   Business                  10  \n",
       "1   Business                  10  \n",
       "2   Business                  10  \n",
       "3   Business                  10  \n",
       "4   Business                  10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_full_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lbl2Vec\n",
    "\n",
    "Train a new model from scratch with the following parameters:\n",
    "* keywords_list : iterable list of lists with descriptive keywords for each topic.\n",
    "* tagged_documents : iterable list of [gensim.models.doc2vec.TaggedDocument](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.TaggedDocument) elements. Each element consists of one document.\n",
    "* label_names : iterable list of custom names for each label. Label names and keywords of the same topic must have the same index.\n",
    "* similarity_threshold : only documents with a higher similarity to the respective description keywords than this treshold are used to calculate the label embedding.\n",
    "* min_num_docs : minimum number of documents that are used to calculate the label embedding. \n",
    "* epochs : number of iterations over the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model with parameters\n",
    "lbl2vec_model = Lbl2Vec(keywords_list=list(labels['keywords']), tagged_documents=ag_full_corpus['tagged_docs'][ag_full_corpus['data_set_type']=='train'], label_names=list(labels['class_name']), similarity_threshold=0.30, min_num_docs=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 08:58:26,472 - Lbl2Vec - INFO - Train document and word embeddings\n",
      "2021-07-20 09:00:21,881 - Lbl2Vec - INFO - Train label embeddings\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "lbl2vec_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict topics of documents used to train Lbl2Vec\n",
    "\n",
    "Compute similarity scores of learned document vectors from documents that were used to train the model to each of the learned label vectors. The similarity scores consist of cosine similarities and therefore have a value range of [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 09:01:58,297 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2021-07-20 09:01:58,476 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "# predict similarity scores\n",
    "model_docs_lbl_similarities = lbl2vec_model.predict_model_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>World</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Business</th>\n",
       "      <th>Science/Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.435321</td>\n",
       "      <td>0.286335</td>\n",
       "      <td>0.435321</td>\n",
       "      <td>0.416035</td>\n",
       "      <td>0.417741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.455163</td>\n",
       "      <td>0.207111</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.441148</td>\n",
       "      <td>0.455163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.519264</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.348006</td>\n",
       "      <td>0.519264</td>\n",
       "      <td>0.409859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>World</td>\n",
       "      <td>0.548215</td>\n",
       "      <td>0.548215</td>\n",
       "      <td>0.142131</td>\n",
       "      <td>0.358767</td>\n",
       "      <td>0.266806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.409460</td>\n",
       "      <td>0.341938</td>\n",
       "      <td>0.369328</td>\n",
       "      <td>0.409460</td>\n",
       "      <td>0.328527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key  most_similar_label  highest_similarity_score     World    Sports  \\\n",
       "0       0              Sports                  0.435321  0.286335  0.435321   \n",
       "1       1  Science/Technology                  0.455163  0.207111  0.295462   \n",
       "2       2            Business                  0.519264  0.268941  0.348006   \n",
       "3       3               World                  0.548215  0.548215  0.142131   \n",
       "4       4            Business                  0.409460  0.341938  0.369328   \n",
       "\n",
       "   Business  Science/Technology  \n",
       "0  0.416035            0.417741  \n",
       "1  0.441148            0.455163  \n",
       "2  0.519264            0.409859  \n",
       "3  0.358767            0.266806  \n",
       "4  0.409460            0.328527  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction of documents used to train Lbl2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DataFrames to compare the predicted and true topic labels\n",
    "evaluation_train = model_docs_lbl_similarities.merge(ag_full_corpus[ag_full_corpus['data_set_type']=='train'], left_on='doc_key', right_on='doc_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8255416666666666\n"
     ]
    }
   ],
   "source": [
    "y_true_train = evaluation_train['class_name']\n",
    "y_pred_train = evaluation_train['most_similar_label']\n",
    "print('F1 score:',f1_score(y_true_train, y_pred_train, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict topics of unknown documents\n",
    "\n",
    "Learn document vectors of new documents that were **not** used to train the model and compute the similarity scores to each of the learned label vectors. The similarity scores consist of cosine similarities and therefore have a value range of [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 09:03:57,434 - Lbl2Vec - INFO - Calculate document embeddings\n",
      "2021-07-20 09:04:01,631 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "# predict similarity scores of new test documents (they were not used during Lbl2Vec training)\n",
    "new_docs_lbl_similarities = lbl2vec_model.predict_new_docs(tagged_docs=ag_full_corpus['tagged_docs'][ag_full_corpus['data_set_type']=='test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>World</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Business</th>\n",
       "      <th>Science/Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120000</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.339817</td>\n",
       "      <td>0.333314</td>\n",
       "      <td>0.241052</td>\n",
       "      <td>0.339817</td>\n",
       "      <td>0.256396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120001</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.370131</td>\n",
       "      <td>0.240881</td>\n",
       "      <td>0.293863</td>\n",
       "      <td>0.305717</td>\n",
       "      <td>0.370131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120002</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.407080</td>\n",
       "      <td>0.241578</td>\n",
       "      <td>0.297648</td>\n",
       "      <td>0.350758</td>\n",
       "      <td>0.407080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120003</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.349194</td>\n",
       "      <td>0.208357</td>\n",
       "      <td>0.349194</td>\n",
       "      <td>0.275795</td>\n",
       "      <td>0.297635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120004</td>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>0.339072</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.257425</td>\n",
       "      <td>0.325634</td>\n",
       "      <td>0.339072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key  most_similar_label  highest_similarity_score     World    Sports  \\\n",
       "0  120000            Business                  0.339817  0.333314  0.241052   \n",
       "1  120001  Science/Technology                  0.370131  0.240881  0.293863   \n",
       "2  120002  Science/Technology                  0.407080  0.241578  0.297648   \n",
       "3  120003              Sports                  0.349194  0.208357  0.349194   \n",
       "4  120004  Science/Technology                  0.339072  0.318110  0.257425   \n",
       "\n",
       "   Business  Science/Technology  \n",
       "0  0.339817            0.256396  \n",
       "1  0.305717            0.370131  \n",
       "2  0.350758            0.407080  \n",
       "3  0.275795            0.297635  \n",
       "4  0.325634            0.339072  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction of new documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DataFrames to compare the predicted and true topic labels\n",
    "evaluation_test = new_docs_lbl_similarities.merge(ag_full_corpus[ag_full_corpus['data_set_type']=='test'], left_on='doc_key', right_on='doc_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8196052631578947\n"
     ]
    }
   ],
   "source": [
    "y_true_test = evaluation_test['class_name']\n",
    "y_pred_test = evaluation_test['most_similar_label']\n",
    "print('F1 score:',f1_score(y_true_test, y_pred_test, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
